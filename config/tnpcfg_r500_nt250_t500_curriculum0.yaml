device: 0
save_dir : 'log'

data:
  train_file: 'data/ptb-train.pickle'
  val_file: 'data/ptb-val.pickle'
  test_file: 'data/ptb-test.pickle'
  use_cache: 0
  cache: 0
  vocab_cache: 'data/ptb-vocab.pickle'
  train_dataset_cache: 'data/ptb-train-cache.pickle'
  val_dataset_cache: 'data/ptb-val-cache.pickle'
  test_dataset_cache: 'data/ptb-val-cache.pickle'
  vocab_type: 'max_size'
  vocab_size: 10000
  min_freq: 2

model:
  model_name: 'TNPCFG'
  NT: 250
  T: 500
  r_dim: 500
  s_dim: 256
  word_emb_size: 200
  shared: 0

train:
  batch_size: 4
  max_epoch: 10
  max_len: 40

  #whether to use curriculum learning stragegy.
  curriculum: 0
  start_len: 20
  increment: 10

  patience: 5
  clip: 3


test:
  batch_size: 8
  max_tokens: 100
  bucket: 32
  # viterbi or mbr
  decode: 'mbr'
  # batch or token
  sampler: 'batch'

optimizer:
  name: 'adam'
  lr: 0.001
  mu: 0.75
  nu: 0.999






